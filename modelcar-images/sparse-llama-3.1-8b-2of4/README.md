# Sparse-Llama-3.1-8B-2of4

https://huggingface.co/neuralmagic/Sparse-Llama-3.1-8B-2of4/tree/main

quay.io/redhat-ai-services/modelcar-catalog:sparse-llama-3.1-8b-2of4

https://neuralmagic.com/blog/24-sparse-llama-smaller-models-for-efficient-gpu-inference/

## Building Image

```
podman build modelcar-images/sparse-llama-3.1-8b-2of4 \
    -t quay.io/redhat-ai-services/modelcar-catalog:sparse-llama-3.1-8b-2of4  \
    --platform linux/amd64
```
